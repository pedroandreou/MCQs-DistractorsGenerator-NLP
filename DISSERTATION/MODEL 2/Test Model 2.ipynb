{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test Model 2.ipynb","provenance":[],"collapsed_sections":["NqiSH20ohpS_","NG06BtF9CufX","uTAnOZHe70W9","4K-TYdnzhfxy","CmLHeeEL80_d","8quqCdQo9JlH","GOLcP0ZR9N2_","g7q30D6B9Siw","EYao2x2ZiW7J","1TVOpzZo9dMx","U02nr6sqirrI","7QUCcTuzaI1n","eV65zIvcaOaJ","ymetFm0eR58s","aZ-1EhG37KdG"],"authorship_tag":"ABX9TyPvqHWYTCB57fdm4qfQbipg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **TEST THE MODEL 2**"],"metadata":{"id":"3UAC2hUAhQwe"}},{"cell_type":"markdown","source":["## Installed Libraries"],"metadata":{"id":"NqiSH20ohpS_"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wItW_OXZ4O99","executionInfo":{"status":"ok","timestamp":1650329079620,"user_tz":-180,"elapsed":83731,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}},"outputId":"b7bd120d-4d99-45b4-e569-18d4011e1880"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 2.1 MB 3.4 MB/s \n","\u001b[?25hProceed (Y/n)? Y\n","\u001b[33mWARNING: Skipping tensorflow-tensorboard as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mProceed (Y/n)? Y\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.5/497.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install --quiet --upgrade pip\n","!pip uninstall --quiet tensorflow tensorflow-tensorboard tensorflow-estimator\n","!pip install --quiet gast==0.2.2\n","!pip install --quiet tensorflow-gpu\n","\n","# Reference: https://stackoverflow.com/questions/69027356/importing-tensorflow-shows-errors\n","\n","# for avoiding error: module 'tensorflow_core.keras.activations' has no attribute 'swish'\n","!pip3 install --quiet --upgrade tensorflow-gpu"]},{"cell_type":"code","source":["!pip install --quiet transformers==4.1.1\n","!pip install --quiet tokenizers==0.9.4\n","!pip install --quiet tensorflow\n","!pip install --quiet sentencepiece==0.1.94\n","!pip install --quiet tqdm==4.56.0\n","!pip install --quiet sense2vec==1.0.2\n","!pip install --quiet gradio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QxLdor6T5PZ0","executionInfo":{"status":"ok","timestamp":1650329172749,"user_tz":-180,"elapsed":90159,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}},"outputId":"b9d9ff60-7e1a-4698-8941-61a26ebaa283"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.2/895.2 KB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.5/497.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.5/253.5 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.9/211.9 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.8/271.8 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 KB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/58.2 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sense2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# in case of error - re-run this cell\n","\n","import torch\n","import tensorflow as tf\n","from transformers import T5ForConditionalGeneration,T5Tokenizer\n","import gradio as gr"],"metadata":{"id":"AE5LVWfz6hTd","executionInfo":{"status":"ok","timestamp":1650329196096,"user_tz":-180,"elapsed":3005,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# connect your personal google drive to store dataset and trained model\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0CNRPr2-4dw6","executionInfo":{"status":"ok","timestamp":1650329220402,"user_tz":-180,"elapsed":20901,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}},"outputId":"7b9a00ad-e18f-4eef-af2d-35d4f722c9d5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["!ls '/content/gdrive/My Drive'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M--mwCAc4cZI","executionInfo":{"status":"ok","timestamp":1650329223505,"user_tz":-180,"elapsed":380,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}},"outputId":"dc066b4c-98b8-4034-87f8-0157e81f6719"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["'Colab Notebooks'   DISSERTATION   Other   Uni\n"]}]},{"cell_type":"code","source":["# need to change dir => so, \"s2v_old\" can be found and be used\n","%cd /content/gdrive/My Drive/DISSERTATION/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNwIdHoO4nAj","executionInfo":{"status":"ok","timestamp":1650329226823,"user_tz":-180,"elapsed":535,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}},"outputId":"69a2dca5-3c1f-4091-956f-b356906af102"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/DISSERTATION\n"]}]},{"cell_type":"code","source":["# Load Sense2Vec Word Embedding\n","from sense2vec import Sense2Vec\n","s2v = Sense2Vec().from_disk('s2v_old')\n","from collections import OrderedDict\n","\n","# Load WordNet Word Embedding\n","import re\n","import nltk\n","nltk.download('wordnet')\n","from nltk.corpus import wordnet as wn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eK3hJbX04oJJ","executionInfo":{"status":"ok","timestamp":1650329256115,"user_tz":-180,"elapsed":28057,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}},"outputId":"3fc8d4fc-db2e-44ca-c2ad-ced0661a5af2"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]}]},{"cell_type":"code","source":["# set seed to reproduce results. Feel free to change the seed though to get different results\n","# it's for the decoding strategies\n","tf.random.set_seed(0)"],"metadata":{"id":"KNd60pjHamc3","executionInfo":{"status":"ok","timestamp":1650329299838,"user_tz":-180,"elapsed":381,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Load the model"],"metadata":{"id":"NG06BtF9CufX"}},{"cell_type":"code","source":["# file path of trained model\n","trained_model_path = '/content/gdrive/My Drive/DISSERTATION/MODEL 2/t5/model/'\n","\n","# file path of trained tokenizer\n","trained_tokenizer_path = '/content/gdrive/My Drive/DISSERTATION/MODEL 2/t5/tokenizer/'"],"metadata":{"id":"C68gyyDr5rqU","executionInfo":{"status":"ok","timestamp":1650329302217,"user_tz":-180,"elapsed":414,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# load the fine-tuned model\n","model = T5ForConditionalGeneration.from_pretrained(trained_model_path)\n","\n","# load the tokenizer\n","tokenizer = T5Tokenizer.from_pretrained(trained_tokenizer_path)"],"metadata":{"id":"iPRMBBoD6c7I","colab":{"base_uri":"https://localhost:8080/","height":396},"executionInfo":{"status":"error","timestamp":1650329314921,"user_tz":-180,"elapsed":12709,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}},"outputId":"f7e05dcb-fbed-4d9b-e9bc-1bc3594d82b1"},"execution_count":11,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-17ff3432993d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the fine-tuned model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load the tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_tokenizer_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 raise OSError(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# in case cuda.is_available() is True => then, the device used is a GPU\n","# otherwise, it's a CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# print what type of the device is used (GPU or CPU)\n","print (\"device \",device)\n","\n","# move the model to the device used (in my case is GPU)\n","model = model.to(device)"],"metadata":{"id":"VCQhVG7m66aL","executionInfo":{"status":"aborted","timestamp":1650329314917,"user_tz":-180,"elapsed":5,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Function for encoding user's input (context and answer)"],"metadata":{"id":"uTAnOZHe70W9"}},{"cell_type":"code","source":["def encode_input(text):\n","    # encode text for feeding it to T5 model\n","    # the keys of the encoded dictionary are [input_ids, attention_mask]\n","    encoding = tokenizer.encode_plus(text,max_length =512, padding=True, return_tensors=\"pt\")\n","\n","    # move the encoded dictionary to the used device (GPU)\n","    input_ids  = encoding[\"input_ids\"].to(device)\n","\n","    return input_ids"],"metadata":{"id":"H66IH5Ij70xT","executionInfo":{"status":"aborted","timestamp":1650329314918,"user_tz":-180,"elapsed":6,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Decoding Strategies for Question Generation"],"metadata":{"id":"4K-TYdnzhfxy"}},{"cell_type":"markdown","source":["### Beam Search"],"metadata":{"id":"CmLHeeEL80_d"}},{"cell_type":"code","source":["def beam_search(input_ids):\n","    \"\"\"\n","    Beam Search Decoding Strategy\n","    \"\"\"\n","\n","    # beams refer to the decoding style used - there are several kinds of decoding methods for generated2text models \n","    beam_outputs = model.generate(\n","        input_ids=input_ids,  # the token ids of the the \"text\" variable above\n","        max_length=72,  # max length of the output \n","\n","        num_beams=5,  # 3 distractors\n","        #no_repeat_ngram_size=3,  # no n-gram will appear three times => the ideal would be to be equal to 2 so no n-gram would appear twice but it ouputs errors\n","        num_return_sequences=1,  # generate one sequence of outputs/distractors\n","        early_stopping=True  # so that the generation is finished when all beam hypotheses reached the EOS token (</s>)\n","    )\n","\n","    return beam_outputs"],"metadata":{"id":"fC0GnxSq820I","executionInfo":{"status":"aborted","timestamp":1650329314919,"user_tz":-180,"elapsed":6,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Greedy Search"],"metadata":{"id":"8quqCdQo9JlH"}},{"cell_type":"code","source":["def greedy_search(input_ids):\n","  \"\"\"\n","  Greedy Search Decoding Strategy\n","  \"\"\"\n","\n","  greedy_output = model.generate(input_ids, max_length=50)\n","\n","  return greedy_output"],"metadata":{"id":"PvV3aCp99I-D","executionInfo":{"status":"aborted","timestamp":1650329314919,"user_tz":-180,"elapsed":6,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Sampling"],"metadata":{"id":"GOLcP0ZR9N2_"}},{"cell_type":"code","source":["def sampling_decoding(input_ids):\n","  \"\"\"\n","  Sampling Decoding Strategy\n","  \"\"\"\n","\n","  # activate sampling and deactivate top_k by setting top_k sampling to 0\n","  sample_output = model.generate(\n","      input_ids, \n","      do_sample=True, \n","      max_length=72, \n","      top_k=0\n","  )\n","\n","  return sample_output"],"metadata":{"id":"udGqsXL79OBn","executionInfo":{"status":"aborted","timestamp":1650329314919,"user_tz":-180,"elapsed":6,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Sampling with Temperature"],"metadata":{"id":"g7q30D6B9Siw"}},{"cell_type":"code","source":["def sampling_with_temperature_decoding(input_ids):\n","  \"\"\"\n","  Sampling with Temperature Decoding Strategy\n","  \"\"\"\n","\n","  # use temperature to decrease the sensitivity to low probability candidates\n","  sample_output = model.generate(\n","      input_ids, \n","      do_sample=True, \n","      max_length=72, \n","      top_k=0, \n","      temperature=0.7\n","  )\n","\n","  return sample_output"],"metadata":{"id":"2QKGG-wk9Sud","executionInfo":{"status":"aborted","timestamp":1650329314920,"user_tz":-180,"elapsed":7,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Top-K Sampling"],"metadata":{"id":"EYao2x2ZiW7J"}},{"cell_type":"code","source":["def topK_sampling(input_ids):\n","  \"\"\"\n","  Top-K Sampling Decoding Method\n","  \"\"\"\n","\n","  # set top_k to 50\n","  sample_output = model.generate(\n","      input_ids, \n","      do_sample=True, \n","      max_length=72, \n","      top_k=50\n","  )\n","\n","  return sample_output"],"metadata":{"id":"a18z1kV89Zrd","executionInfo":{"status":"aborted","timestamp":1650329314920,"user_tz":-180,"elapsed":7,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Top-p (nucleus) Sampling"],"metadata":{"id":"1TVOpzZo9dMx"}},{"cell_type":"code","source":["def nucleus_sampling(input_ids):\n","  \"\"\"\n","  Top-K Sampling Decoding Strategy\n","  \"\"\"\n","\n","  # deactivate top_k sampling and sample only from 92% most likely words\n","  sample_output = model.generate(\n","      input_ids, \n","      do_sample=True, \n","      max_length=72, \n","      top_p=0.92, \n","      top_k=0\n","  )\n","\n","  return sample_output"],"metadata":{"id":"uBCszIDD9dRG","executionInfo":{"status":"aborted","timestamp":1650329314920,"user_tz":-180,"elapsed":7,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Functions for Generating Distractors"],"metadata":{"id":"U02nr6sqirrI"}},{"cell_type":"markdown","source":["### WordNet Word Embedding"],"metadata":{"id":"7QUCcTuzaI1n"}},{"cell_type":"code","source":["def get_distractors_wordnet(word):\n","    \n","    \"\"\"\n","    This function is called when the WordNet radiobutton is selected by the user\n","\n","    Finds hyponynms of the given answer/word \n","    Returns 3 distractors\n","    \"\"\"\n","\n","    distractors=[] # initalize a list for adding the distractors of the given word\n","\n","    try:\n","      syn = wn.synsets(word,'n')[0] # get noun synonyms => thus, 'n'\n","    \n","      word = word.lower() # make the word lowercase\n","      orig_word = word # original word is the lowercased word\n","\n","      # if the word can be split => replace the space with an underscore\n","      if len(word.split()) > 0:\n","          word = word.replace(\" \", \"_\")\n","\n","      # hypernym is the higher-level category => we are looking for hyponyms - sub-categories\n","      hypernym = syn.hypernyms()\n","\n","      # if hypernym is 0 => the given word is in the higher-level category and not in the subcategory => return an empty list of distractors => no distractors found\n","      if len(hypernym) == 0:\n","          return distractors\n","      for item in hypernym[0].hyponyms():\n","          name = item.lemmas()[0].name()\n","          print (\"name \",name)\n","\n","          # check if the hyponym found is the same with the word given => if yes, check for other hyponyms\n","          if name == orig_word:\n","              continue\n","\n","          # if no, replace the underscore to a space\n","          name = name.replace(\"_\", \" \")\n","          # join the splitted words to one string\n","          name = \" \".join(w.capitalize() for w in name.split())\n","\n","          # check that the found hyponym is not empty and the is not already in the list => append it to the list\n","          if name is not None and name not in distractors:\n","              distractors.append(name)\n","    except: # in case the given word has no synsets (set of synonyms) => exception\n","      print (\"Wordnet distractors not found\")\n","\n","\n","    # return the first 3 distractors\n","    return distractors[:3]"],"metadata":{"id":"LivAI2ohiyCU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Sense2Vec Word Embedding"],"metadata":{"id":"eV65zIvcaOaJ"}},{"cell_type":"code","source":["def get_distractors_sense2vec(word):\n","\n","  \"\"\"\n","    This function is called when the Sense2Vec radiobutton is selected by the user\n","\n","    returns 3 distractors\n","  \"\"\"\n","\n","  output = []\n","  word = word.lower()\n","  word = word.replace(\" \", \"_\")\n","\n","  sense = s2v.get_best_sense(word)\n","      \n","  if not sense: # check if the word has no sense => return\n","      return None\n","  else: \n","      most_similar = s2v.most_similar(sense, n=3)\n","      \n","\n","  for each_word in most_similar:\n","      append_word = each_word[0].split(\"|\")[0].replace(\"_\", \" \").lower()\n","      \n","      \n","      if append_word.lower() != word:\n","          output.append(append_word.title())\n","      \n","  out = list(OrderedDict.fromkeys(output))\n","\n","  return out"],"metadata":{"id":"tsmosfzdi0eu","executionInfo":{"status":"ok","timestamp":1650329324334,"user_tz":-180,"elapsed":2,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## Prepare GUI"],"metadata":{"id":"ymetFm0eR58s"}},{"cell_type":"code","source":["context = gr.inputs.Textbox(lines=2, placeholder=\"Enter context/passage here...\")\n","answer = gr.inputs.Textbox(lines=1, placeholder=\"Enter right answer here...\")\n","decoding_strategy = gr.inputs.Radio([\"Beam Search\", \"Greedy Search\", \"Sampling\", \"Sampling w Temp\", \"Top-K\", \"Top-p\"])\n","word_embedding = gr.inputs.Radio([\"Wordnet\", \"Sense2Vec\"])\n","\n","\n","displayed_output = gr.outputs.HTML(label=\"PASSAGE, ANSWER, QUESTION\")"],"metadata":{"id":"HAP1qM5bQVU2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def second_model(context, answer, decoding_strategy, word_embedding):\n","    text = \"context: \"+context + \" \" + \"answer: \" + answer + \" </s>\"\n","\n","    input_ids = encode_input(text)\n","\n","    # place the model in evaluation mode => inference\n","    model.eval()\n","\n","\n","    # get the generated output => the question\n","    if decoding_strategy == \"Beam Search\":\n","      generated_output = beam_search(input_ids)\n","    elif decoding_strategy == \"Greedy Search\":\n","      generated_output = greedy_search(input_ids)\n","    elif decoding_strategy == \"Sampling\":\n","      generated_output = sampling_decoding(input_ids)\n","    elif decoding_strategy == \"Sampling w Temp\":\n","      generated_output = sampling_decoding(input_ids)    \n","    elif decoding_strategy == \"Top-K\":\n","      generated_output = topK_sampling(input_ids)   \n","    elif decoding_strategy == \"Top-p\":\n","      generated_output = nucleus_sampling(input_ids)   \n","\n","    # decode the generated output\n","    decoded_output = tokenizer.decode(generated_output[0], skip_special_tokens=True)\n","\n","\n","    # if Wordnet is selected => call get_distractors_wordnet() function => get distractors from wordnet for the specific keyword/answer\n","    if word_embedding==\"Wordnet\":\n","      distractors = get_distractors_wordnet(answer)\n","    else:\n","      # Othwerise, sense2vec is selected => call get_distractors() function => get distractors from Sense2Vec for the specific keyword/answer\n","      distractors = get_distractors_sense2vec(answer)\n","\n","\n","    # question\n","    # [10:] => the string part of ---\"question:\"---  from \"question: {question}\" will be skipped\n","    displayed_output = f\"<p> <b style='color:blue;'> {decoded_output[10:]} </b> </p>\" \n","\n","\n","    # question + \\n + answer\n","    displayed_output = f\"{displayed_output}<p> <b style='color:green;'> {answer} </b> </p>\"\n","\n","\n","    # question + \\n + answer + \\n + distractors\n","    if distractors is not None and len(distractors) == 3:\n","      for distractor in distractors:\n","        displayed_output = displayed_output + \"<b style='color:brown;'>\" + distractor+  \"</b>\"+\"<br>\"\n","\n","    # question + \\n + answer + \\n + distractors + \\n + context\n","    displayed_output = f\"{displayed_output}<p> {context} </b> </p>\"\n","\n","\n","    return displayed_output"],"metadata":{"id":"plPKKNfrjb2i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["face = gr.Interface(\n","    fn = second_model, \n","    inputs = [context, answer, decoding_strategy, word_embedding], \n","    outputs = displayed_output\n",")"],"metadata":{"id":"s3VlLB5zjJBd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Test GUI"],"metadata":{"id":"aZ-1EhG37KdG"}},{"cell_type":"code","source":["# if degug=True => prints the errors in the cell output\n","face.launch(debug=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":750},"id":"BrBIUfCgaYfv","executionInfo":{"status":"ok","timestamp":1649342414590,"user_tz":-180,"elapsed":46477,"user":{"displayName":"Petros A.","userId":"16072483555613838293"}},"outputId":"cb155790-8b8e-4906-fc47-90f38dc567de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","Running on public URL: https://50737.gradio.app\n","\n","This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.lib.display.IFrame at 0x7f3f6980c1d0>"],"text/html":["\n","        <iframe\n","            width=\"900\"\n","            height=\"500\"\n","            src=\"https://50737.gradio.app\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:184: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n","  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated eos tokens being added.\"\n","/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1065: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"output_type":"stream","name":"stdout","text":["Keyboard interruption in main thread... closing server.\n"]},{"output_type":"execute_result","data":{"text/plain":["(<fastapi.applications.FastAPI at 0x7f400a4f8050>,\n"," 'http://127.0.0.1:7860/',\n"," 'https://50737.gradio.app')"]},"metadata":{},"execution_count":46}]}]}