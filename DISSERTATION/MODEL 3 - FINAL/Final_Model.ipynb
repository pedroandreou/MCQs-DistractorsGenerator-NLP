{"cells":[{"cell_type":"markdown","metadata":{"id":"8icxymffAV9p"},"source":["# **THIRD MODEL - STAGE 1**"]},{"cell_type":"markdown","metadata":{"id":"nL33UMx9U_G5"},"source":["## Installed Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52392,"status":"ok","timestamp":1650475490468,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"ugTLysLp787W","outputId":"6506b376-bc76-4a51-d9b2-f37169368361"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 2.5 MB 5.2 MB/s \n","\u001b[K     |████████████████████████████████| 3.3 MB 37.3 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 45.1 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 5.4 MB/s \n","\u001b[K     |████████████████████████████████| 54 kB 2.0 MB/s \n","\u001b[?25h  Building wheel for sense2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 865 kB 5.3 MB/s \n","\u001b[K     |████████████████████████████████| 2.0 MB 40.9 MB/s \n","\u001b[K     |████████████████████████████████| 211 kB 50.3 MB/s \n","\u001b[K     |████████████████████████████████| 856 kB 40.8 MB/s \n","\u001b[K     |████████████████████████████████| 61 kB 453 kB/s \n","\u001b[K     |████████████████████████████████| 3.6 MB 34.6 MB/s \n","\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for flask-cachebuster (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 235 kB 5.3 MB/s \n","\u001b[?25h  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install --quiet transformers==4.8.1\n","!pip install --quiet sentencepiece==0.1.95\n","!pip install --quiet textwrap3==0.9.2\n","!pip install --quiet nltk==3.2.5\n","!pip install --quiet sense2vec==1.0.2\n","!pip install --quiet gradio==2.7.0\n","\n","# install keyphrase extraction toolkit\n","!pip install --quiet git+https://github.com/boudinfl/pke.git@dc4d5f21e0ffe64c4df93c46146d29d1c522476b\n","\n","# lib created specifically for the purpose of searching and replacing words in a document\n","!pip install --quiet flashtext==2.7"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5290,"status":"ok","timestamp":1650475495751,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"_P3A6bpGJ_Pc","outputId":"e7ed767b-1923-4b82-953e-15920ed8d462"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 194 µs (started: 2022-04-20 17:24:54 +00:00)\n"]}],"source":["# lib for timing everything/every running cell\n","!pip install --quiet ipython-autotime\n","\n","# turn it on\n","%load_ext autotime"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1650475495752,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"p-Oi4poCjfrZ","outputId":"e3eb1399-920a-4fcc-95e2-5579b28ffc2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 7.62 ms (started: 2022-04-20 17:24:54 +00:00)\n"]}],"source":["# for printing each line of the summary at most width characters long\n","from textwrap3 import wrap"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22639,"status":"ok","timestamp":1650475518386,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"Txne56cRi29x","outputId":"ca5bc331-414b-4b78-e2d0-4ba763430cc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n","time: 22.5 s (started: 2022-04-20 17:24:54 +00:00)\n"]}],"source":["# connect your personal google drive to load the trained model and tokenizer of question generation\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":339,"status":"ok","timestamp":1650475518719,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"wayVz8JGbksq","outputId":"e52b02b9-b259-40c7-c719-88227d36a661"},"outputs":[{"name":"stdout","output_type":"stream","text":["'Colab Notebooks'   DISSERTATION   Other   Uni\n","time: 125 ms (started: 2022-04-20 17:25:17 +00:00)\n"]}],"source":["!ls '/content/gdrive/My Drive'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1650475518719,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"MJbtGF8obpBT","outputId":"b4d7a681-9b76-40bc-ba55-088ec7095db0"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/My Drive/DISSERTATION\n","time: 8.75 ms (started: 2022-04-20 17:25:17 +00:00)\n"]}],"source":["# need to change dir => so, \"s2v_old\" can be found and be used\n","%cd /content/gdrive/My Drive/DISSERTATION/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19861,"status":"ok","timestamp":1650475538579,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"D5rv7A1ibp_l","outputId":"2a064b60-5dea-4d57-e723-7b64476ed1a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 20 s (started: 2022-04-20 17:25:17 +00:00)\n"]}],"source":["from sense2vec import Sense2Vec\n","s2v = Sense2Vec().from_disk('s2v_old')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10250,"status":"ok","timestamp":1650475548827,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"AKd_ptGCLjin","outputId":"89226e42-e25e-4d37-c899-0fb307fcc95c"},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","time: 10.2 s (started: 2022-04-20 17:25:37 +00:00)\n"]}],"source":["import torch\n","from transformers import T5ForConditionalGeneration,T5Tokenizer\n","\n","import random\n","import numpy as np\n","\n","import nltk\n","nltk.download('punkt') # this tokenizer divides a text into a list of sentences, by using an unsupervised algorithm\n","nltk.download('brown')\n","nltk.download('wordnet')\n","\n","from nltk.corpus import wordnet as wn\n","from nltk.tokenize import sent_tokenize\n","\n","import nltk\n","nltk.download('stopwords') # stop words are the most common words => do not add much meaning to a sentence\n","from nltk.corpus import stopwords\n","import string\n","\n","# OrderedDict is a dictionary that helps to remember the order of the keys that were inserted first\n","from collections import OrderedDict\n","\n","# lib for the keyword extraction\n","import pke\n","\n","# lib used for printing exception stack trace\n","import traceback\n","\n","from flashtext import KeywordProcessor\n","\n","import gradio as gr"]},{"cell_type":"markdown","metadata":{"id":"n5EKQ4r7KEJf"},"source":["## Download our pretrained model and tokenizer for summarization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5498,"status":"ok","timestamp":1650475625359,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"5BQo3W8eNAuH","outputId":"38849b1d-2b5b-4db9-fbd1-e082d58d7a68"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 5.27 s (started: 2022-04-20 17:26:59 +00:00)\n"]}],"source":["# download our pre-trained model\n","summary_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n","\n","# download our pre-trained tokenizer\n","summary_tokenizer = T5Tokenizer.from_pretrained('t5-base')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":341,"status":"ok","timestamp":1650475625697,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"hFxjaM5RNCKT","outputId":"39626023-a15d-40c9-ba8c-713c98279992"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 436 ms (started: 2022-04-20 17:27:04 +00:00)\n"]}],"source":["# in case cuda.is_available() is True => then, the device used is a GPU\n","# otherwise, it's a CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# move the model to the device used (in my case is GPU)\n","summary_model = summary_model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"dvaYa_e5epC3"},"source":["## Set seed"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1650475625697,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"wkoOjjqcKIHP","outputId":"da2ef241-1511-4d53-8e48-698baddc4357"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 5.73 ms (started: 2022-04-20 17:27:04 +00:00)\n"]}],"source":["# Difference between torch.manual_seed & torch.cuda.manual_seed_all - THREAD: https://discuss.pytorch.org/t/difference-between-torch-manual-seed-and-torch-cuda-manual-seed/13848/7\n","\n","def set_seed(seed: int):\n","    \"\"\" \n","      This function sets the same seed  to be able to reproduce the results\n","      as each algorithm uses its own random number generator  \n","    \"\"\"\n","\n","    random.seed(seed) # set python built-in pseudo-random generator at a fixed value\n","    np.random.seed(seed) # set numpy pseudo-random generator at a fixed value\n","    torch.manual_seed(seed) # pytorch pseudo-random generator at a fixed value\n","    torch.cuda.manual_seed_all(seed) # for having reproducible results when using random generation on the gpu\n","\n","\n","set_seed(42)"]},{"cell_type":"markdown","metadata":{"id":"vWeUtAiDexVo"},"source":["## Summary preprocessing, encoding, generation, decoding, postprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1650475625698,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"esuci_NuKKXJ","outputId":"6d50c29a-67f2-46ac-e3e9-2a0209280e23"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 7.82 ms (started: 2022-04-20 17:27:04 +00:00)\n"]}],"source":["def post_process_text (content):\n","  \"\"\"\n","    This function tokenizes sentences and then capitalize the first letter of the first word of the sentence \n","    by making the rest characters of that sentence to lowercase\n","  \"\"\"\n","\n","  final=\"\"\n","\n","  # example: https://pythonspot.com/tokenizing-words-and-sentences-with-nltk/ (Section: Tokenizing sentences)\n","  for sent in sent_tokenize(content):\n","    sent = sent.capitalize()\n","    final = final +\" \"+sent\n","\n","    \n","  return final"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":221,"status":"ok","timestamp":1650475625916,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"hUsFUnbhh33M","outputId":"34b238af-6a5d-4280-8e9a-3f4e4490c73a"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 40 ms (started: 2022-04-20 17:27:04 +00:00)\n"]}],"source":["def summarizer(context,model,tokenizer):\n","  \"\"\" \n","    this function's main purpose is to generate the summary of the text by taking the following steps:\n","      1. encode the given original text\n","      2. generate its summary according to the encoded input \n","      3. decode the generated summary\n","      4. process the summary by sending it to the post_process_text() function as well as removing any leading and trailing whitespaces\n","      5. return the final version of the summary\n","  \"\"\"\n","\n","  context = context.strip().replace(\"\\n\",\" \")\n","  input = \"summarize: \"+ context # summarize string prefix added\n","\n","\n","  encoding = tokenizer.encode_plus(input, max_length=512, pad_to_max_length=False,truncation=True, return_tensors=\"pt\").to(device)\n","\n","  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n","\n","\n","  # hugging face generate function generates a summary of minimum 75 tokens and 300 max\n","  outs = model.generate(input_ids=input_ids,\n","                                  attention_mask=attention_mask,\n","                                  early_stopping=True,\n","                                  num_beams=3,\n","                                  num_return_sequences=1,\n","                                  no_repeat_ngram_size=2,\n","                                  min_length = 75,\n","                                  max_length=300)\n","\n","\n","  # decode the generated summary \n","  dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n","  summary = dec[0] # [0] is for getting it out of the square brackets\n","\n","  # call the post_process_text function to process the text\n","  summary = post_process_text(summary)\n","\n","  # remove leading and trailing whitespaces\n","  summary= summary.strip()\n","\n","\n","  return summary"]},{"cell_type":"markdown","metadata":{"id":"I51vKezENsue"},"source":["## Answer Span Extraction (Keywords and Noun Phrases)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1650475625917,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"pZUDFImCiCNa","outputId":"9b85a8d5-bcd3-4c6c-fb9c-11b872950806"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 60.3 ms (started: 2022-04-20 17:27:05 +00:00)\n"]}],"source":["def get_nouns_multipartite(content):\n","    \"\"\" \n","      extract keywords using multipartite algorithm\n","    \"\"\"\n","\n","    out=[]\n","\n","    try:\n","        extractor = pke.unsupervised.MultipartiteRank()\n","        extractor.load_document(input=content)\n","\n","        pos = {'PROPN','NOUN'}\n","\n","        # not contain punctuation marks or stopwords as candidates.\n","        stoplist = list(string.punctuation)\n","        stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n","        stoplist += stopwords.words('english')\n","        extractor.candidate_selection(pos=pos, stoplist=stoplist)\n","\n","\n","        # build the Multipartite graph and rank candidates using random walk,\n","        # alpha controls the weight adjustment mechanism\n","        # see TopicRank for threshold/method parameters.\n","        extractor.candidate_weighting(alpha=1.1,\n","                                      threshold=0.75,\n","                                      method='average')\n","        \n","        keyphrases = extractor.get_n_best(n=15)\n","\n","        print(\"n_best keyphrases: \", keyphrases)\n","        \n","\n","        for val in keyphrases:\n","            out.append(val[0])\n","    except:\n","        out = []\n","        traceback.print_exc()\n","\n","\n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1650475625917,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"ft9DmG8ybN95","outputId":"85e57bca-1337-4b7b-8e9d-8a2c31f0b3c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 39.3 ms (started: 2022-04-20 17:27:05 +00:00)\n"]}],"source":["def get_keywords(originaltext,summarytext):\n","  \"\"\" \n","    this function's mainly purpose is to find the keywords that are in both original text and summarized text\n","    >>> returns the first 4 keywords of the list\n","    \n","    Steps:\n","      1. calls the get_noun_multipartite function to extract keywords from the original text\n","      2. adds those extracted keywords of the original text to the keyword processor\n","      3. extracts keywords from the summarized text using the processor\n","      4. checks if the extracted keywords from the original text are in the summarized text => keep  --- Otherwise => ignore\n","  \"\"\"\n","\n","  # call the function to extract keywords from the original text\n","  keywords = get_nouns_multipartite(originaltext)\n","  \n","  # print the original text's extracted keywords\n","  print (\"keywords of the original text: \",keywords)\n","\n","  # initialize keyword processor\n","  keyword_processor = KeywordProcessor()\n","  # add original text's extracted keywords to the keyword processor\n","  for keyword in keywords:\n","    keyword_processor.add_keyword(keyword)\n","\n","  # exract keywords from the summarized text\n","  keywords_found = keyword_processor.extract_keywords(summarytext)\n","  # add the summarized text's extracted keywords to a list\n","  keywords_found = list(set(keywords_found))\n","  \n","  print (\"keywords of the summarized text: \",keywords_found)\n","\n","\n","  important_keywords = [] # list for containing the extracted keywords that are contained in both original and summarized texts\n","\n","  # check if any of the original text's extracted keywords matches to the summarized text's extracted keywords => add it to the list\n","  for keyword in keywords:\n","    if keyword in keywords_found:\n","      important_keywords.append(keyword) \n","\n","\n","  # return only 4 matched keywords\n","  return important_keywords[:4] "]},{"cell_type":"markdown","metadata":{"id":"Kul4z9SBbT3T"},"source":["## Load our Fine-Tuned Question Generation T5 model (our 2nd model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19557,"status":"ok","timestamp":1650475645915,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"znG9x4srbP6o","outputId":"c1634baa-34bb-4053-c690-39f6bdc07efb"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 19.4 s (started: 2022-04-20 17:27:05 +00:00)\n"]}],"source":["# load our pre-trained T5 model for question generation\n","question_model = T5ForConditionalGeneration.from_pretrained('/content/gdrive/My Drive/DISSERTATION/MODEL 2/t5/model')\n","\n","# load our pre-trained T5 tokenizer for question generation\n","question_tokenizer = T5Tokenizer.from_pretrained('/content/gdrive/My Drive/DISSERTATION/MODEL 2/t5/tokenizer')\n","\n","\n","# move the model to the device used (in my case is GPU)\n","question_model = question_model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"OXAaiQNVQyrS"},"source":["## Decoding Strategies"]},{"cell_type":"markdown","metadata":{"id":"xkmWZEQqIya9"},"source":["### Beam Search"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1650475645916,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"_Coziy4vIzmp","outputId":"bc482585-106a-48b7-864b-4146649b98ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 3.43 ms (started: 2022-04-20 17:27:25 +00:00)\n"]}],"source":["def beam_search(input_ids):\n","    \"\"\"\n","    Beam Search Decoding Strategy\n","    \"\"\"\n","\n","    # beams refer to the decoding style used - there are several kinds of decoding methods for generated2text models \n","    outs = question_model.generate(\n","        input_ids=input_ids,  # the token ids of the the \"text\" variable above\n","        max_length=72,  # max length of the output \n","\n","        num_beams=5,  # 3 distractors\n","        no_repeat_ngram_size=3,  # no n-gram will appear three times => the ideal would be to be equal to 2 so no n-gram would appear twice but it ouputs errors\n","        num_return_sequences=1,  # generate one sequence of outputs/distractors\n","        early_stopping=True  # so that the generation is finished when all beam hypotheses reached the EOS token (</s>)\n","    )\n","\n","\n","    return outs"]},{"cell_type":"markdown","metadata":{"id":"yjApievUI5BR"},"source":["### Greedy Search"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1650475645916,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"2_Q0jbCOI8Kw","outputId":"2c8cb14d-36fd-4873-855c-bdc33f51ef97"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 1.8 ms (started: 2022-04-20 17:27:25 +00:00)\n"]}],"source":["def greedy_search(input_ids):\n","  \"\"\"\n","  Greedy Search Decoding Strategy\n","  \"\"\"\n","\n","  outs = question_model.generate(input_ids, max_length=50)\n","\n","\n","  return outs"]},{"cell_type":"markdown","metadata":{"id":"kQQcHzdpI9-V"},"source":["### Random Sampling"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1650475645916,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"ktF4uGdEI_m7","outputId":"c1495f8f-b43f-4886-f624-1707ba5cda05"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 7.4 ms (started: 2022-04-20 17:27:25 +00:00)\n"]}],"source":["def sampling_decoding(input_ids):\n","  \"\"\"\n","  Sampling Decoding Strategy\n","  \"\"\"\n","\n","  # activate sampling and deactivate top_k by setting top_k sampling to 0\n","  outs = question_model.generate(\n","      input_ids, \n","      do_sample=True, \n","      max_length=72, \n","      top_k=0\n","  )\n","\n","\n","  return outs"]},{"cell_type":"markdown","metadata":{"id":"x_onxX5hJBMX"},"source":["### Random Sampling with Temperature"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1650475645917,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"stl95_BwJIda","outputId":"f45b2f97-4769-480d-9e08-4468fba49056"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 5.71 ms (started: 2022-04-20 17:27:25 +00:00)\n"]}],"source":["def sampling_with_temperature_decoding(input_ids):\n","  \"\"\"\n","  Sampling with Temperature Decoding Strategy\n","  \"\"\"\n","\n","  # use temperature to decrease the sensitivity to low probability candidates\n","  outs = question_model.generate(\n","      input_ids, \n","      do_sample=True, \n","      max_length=72, \n","      top_k=0, \n","      temperature=0.7\n","  )\n","\n","\n","  return outs"]},{"cell_type":"markdown","metadata":{"id":"yKdFjuBRJJ2J"},"source":["### Top-K Sampling"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1650475645917,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"dHKB5m0EJOfu","outputId":"d56d5ab0-f118-484c-b901-6f511d01df79"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 6.89 ms (started: 2022-04-20 17:27:25 +00:00)\n"]}],"source":["def topK_sampling(input_ids):\n","  \"\"\"\n","  Top-K Sampling Decoding Strategy\n","  \"\"\"\n","\n","  # set top_k to 50\n","  outs = question_model.generate(\n","      input_ids, \n","      do_sample=True, \n","      max_length=72, \n","      top_k=50\n","  )\n","\n","  return outs"]},{"cell_type":"markdown","metadata":{"id":"2hc7kP7bJQOz"},"source":["### Top-p (nucleus) Sampling"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1650475645918,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"lU0Ydtw_JWpn","outputId":"a5897d46-21d8-421a-acde-672ef2b01a90"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 5.1 ms (started: 2022-04-20 17:27:25 +00:00)\n"]}],"source":["def nucleus_sampling(input_ids):\n","  \"\"\"\n","  Top-K Sampling Decoding Strategy\n","  \"\"\"\n","\n","  # deactivate top_k sampling and sample only from 92% most likely words\n","  outs = question_model.generate(\n","      input_ids, \n","      do_sample=True, \n","      max_length=72, \n","      top_p=0.92, \n","      top_k=0\n","  )\n","\n","\n","  return outs"]},{"cell_type":"markdown","metadata":{"id":"OgCr8K7hJ_bk"},"source":["## Function for encoding the input, passing it to the selected Decoding Strategy and decoding the new genereated output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1650475645918,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"v-8l1D1deg_3","outputId":"af8333a1-6b00-45ad-db6e-e28438d1ec69"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 29.6 ms (started: 2022-04-20 17:27:25 +00:00)\n"]}],"source":["def get_question(context,answer,model,tokenizer, decoding_method):\n","  \"\"\"\n","  this function's purpose is to generate questions using the our T5 pre-trained model\n","  \n","  Steps:\n","  1. encodes both summarized text and answer which are passed to the selected Decoding Strategy\n","  2. generate a question\n","  3. decode the generated question\n","  \"\"\"\n","\n","\n","  text = \"context: {} answer: {}\".format(context,answer)\n","  encoding = tokenizer.encode_plus(text,max_length=384, pad_to_max_length=False,truncation=True, return_tensors=\"pt\").to(device)\n","  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n","\n","  outs = \"\"\n","\n","  # get the generated output from the selected decoding method\n","  if decoding_method == \"Beam Search\":\n","    outs = beam_search(input_ids)\n","  elif decoding_method == \"Greedy Search\":\n","    outs = greedy_search(input_ids)\n","  elif decoding_method == \"Sampling\":\n","    outs = sampling_decoding(input_ids)\n","  elif decoding_method == \"Sampling w Temp\":\n","    outs = sampling_decoding(input_ids)    \n","  elif decoding_method == \"Top-K\":\n","    outs = topK_sampling(input_ids)   \n","  elif decoding_method == \"Top-p\":\n","    outs = nucleus_sampling(input_ids)  \n","\n","\n","  # decode the generated output => question\n","  dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs] # decode the generated question\n","\n","  Question = dec[0].replace(\"question:\",\"\") # skip the string \"question:\" => contain only the real question\n","  \n","  Question= Question.strip() #  remove leading and trailing whitespaces\n","\n","\n","  return Question"]},{"cell_type":"markdown","metadata":{"id":"jm4PVXSoRRBb"},"source":["## Word Embedding functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":345,"status":"ok","timestamp":1650475646257,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"lwEwCy1LZlUO","outputId":"fef0edb0-1006-4df6-979c-0144c1607b17"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 17.6 ms (started: 2022-04-20 17:27:25 +00:00)\n"]}],"source":["def get_distractors_wordnet (word):\n","    \n","    \"\"\"\n","    This function is called when the WordNet radiobutton is selected by the user\n","\n","    Finds hyponynms of the given answer/word \n","    Returns 3 distractors\n","    \"\"\"\n","\n","    distractors=[] # initalize a list for adding the distractors of the given word\n","\n","    try:\n","      syn = wn.synsets(word,'n')[0] # get noun synonyms => thus, 'n'\n","    \n","      word = word.lower() # make the word lowercase\n","      orig_word = word # original word is the lowercased word\n","\n","      # if the word can be split => replace the space with an underscore\n","      if len(word.split()) > 0:\n","          word = word.replace(\" \", \"_\")\n","\n","      # hypernym is the higher-level category => we are looking for hyponyms - sub-categories\n","      hypernym = syn.hypernyms()\n","\n","      # if hypernym is 0 => the given word is in the higher-level category and not in the subcategory => return an empty list of distractors => no distractors found\n","      if len(hypernym) == 0:\n","          return distractors\n","      for item in hypernym[0].hyponyms():\n","          name = item.lemmas()[0].name()\n","          # print (\"name \",name, \" word\",orig_word)\n","\n","          # check if the hyponym found is the same with the word given => if yes, check for other hyponyms\n","          if name == orig_word:\n","              continue\n","\n","          # if no, replace the underscore to a space\n","          name = name.replace(\"_\", \" \")\n","          # join the splitted words to one string\n","          name = \" \".join(w.capitalize() for w in name.split())\n","\n","          # check that the found hyponym is not empty and the is not already in the list => append it to the list\n","          if name is not None and name not in distractors:\n","              distractors.append(name)\n","    except: # in case the given word has no synsets (set of synonyms) => exception\n","      print (\"Wordnet distractors not found\")\n","\n","\n","    # return distractors\n","    return distractors[:3]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1650475646258,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"Py7pB5_JRVCv","outputId":"b389c55a-41b6-40f8-e655-2bd8b1275dfb"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 11.5 ms (started: 2022-04-20 17:27:25 +00:00)\n"]}],"source":["def get_distractors_sense2vec (word):\n","\n","  \"\"\"\n","    This function is called when the Sense2Vec radiobutton is selected by the user\n","\n","    returns 3 distractors\n","  \"\"\"\n","\n","  output = []\n","  word = word.lower()\n","  word = word.replace(\" \", \"_\")\n","\n","  sense = s2v.get_best_sense(word)\n","\n","  if not sense: # check if the word has no sense => return\n","    return \" \"\n","  else: \n","    most_similar = s2v.most_similar(sense, n=3)\n","\n","  # print (\"most_similar \",most_similar)\n","\n","  for each_word in most_similar:\n","      append_word = each_word[0].split(\"|\")[0].replace(\"_\", \" \").lower()\n","\n","      if append_word.lower() != word:\n","          output.append(append_word.title())\n","\n","  out = list(OrderedDict.fromkeys(output))\n","  \n","  return out"]},{"cell_type":"markdown","metadata":{"id":"fLmz4p69C8ZX"},"source":["## Prepare GUI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1650475646258,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"GjN8OcBD8aJV","outputId":"9e8970e7-8012-48ed-d5b2-b8acdfca8c49"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 3.84 ms (started: 2022-04-20 17:27:25 +00:00)\n"]}],"source":["context = gr.inputs.Textbox(lines=10, placeholder=\"Enter paragraph/content here...\")\n","output = gr.outputs.HTML(label=\"Question and Answers\")\n","\n","Decoding_Strategy = gr.inputs.Radio([\"Beam Search\", \"Greedy Search\", \"Sampling\", \"Sampling w Temp\", \"Top-K\", \"Top-p\"])\n","Word_Embedding = gr.inputs.Radio([\"Wordnet\", \"Sense2Vec\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1650475646258,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"BUkf0K2he4ws","outputId":"3b599068-225b-42c4-d72a-e24ee73ad82c"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 33.3 ms (started: 2022-04-20 17:27:25 +00:00)\n"]}],"source":["def third_model_stage1(context, Decoding_Strategy, Word_Embedding):\n","  \n","  # get summary of the user's given text\n","  summary_text = summarizer(context,summary_model,summary_tokenizer)\n","\n","  # print the summary for debugging purposes\n","  for wrp in wrap(summary_text, 150):\n","    print (wrp)\n","  \n","  # get the 4 keywords that are contained in both original text (user's input) and summarized text\n","  np =  get_keywords(context,summary_text)\n","  \n","  # print the keywords\n","  #print (\"\\n\\nNoun phrases\",np)\n","\n","\n","  output=\"\" # initialize an empty string => GUI's output\n","  \n","  # for each keyword => generate a question \n","  for answer in np:\n","    ques = get_question(summary_text,answer,question_model,question_tokenizer, Decoding_Strategy) # generate a question\n","\n","    # if Wordnet is selected => call get_distractors_wordnet() function => get distractors from wordnet for the specific keyword/answer\n","    if Word_Embedding == \"Wordnet\":\n","      distractors = get_distractors_wordnet(answer)\n","    else:\n","      # Othwerise, sense2vec is selected => call get_distractors() function => get distractors from Sense2Vec for the specific keyword/answer\n","      distractors = get_distractors_sense2vec(answer)\n","\n","    # output= output + ques + \"\\n\" + \"Ans: \"+answer.capitalize() + \"\\n\\n\"\n","    output = output + \"<b style='color:blue;'>\" + ques + \"</b>\"\n","    output = output + \"<br>\"\n","    output = output + \"<b style='color:green;'>\" + \"Ans: \" +answer.capitalize()+  \"</b>\"\n","    output = output + \"<br>\"\n","    if len(distractors) > 0:\n","      for distractor in distractors: # add 3 distractors\n","        output = output + \"<b style='color:brown;'>\" + distractor+  \"</b>\"+\"<br>\"\n","    output = output + \"<br>\"\n","\n","  # Summarized text\n","  summary =\"Summary: \"+ summary_text\n","\n","  # make bold the keywords that appear in the summary\n","  for answer in np:\n","    summary = summary.replace(answer,\"<b>\"+answer+\"</b>\")\n","    summary = summary.replace(answer.capitalize(),\"<b>\"+answer.capitalize()+\"</b>\")\n","\n","  # add the summary to the output\n","  output = output + \"<p>\"+summary+\"</p>\"\n","  \n","  return output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":450,"status":"ok","timestamp":1650475646705,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"QMO8EhmsIYeY","outputId":"33ae4059-f474-43d2-f274-3fa75dfa8f1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 703 ms (started: 2022-04-20 17:27:25 +00:00)\n"]}],"source":["iface = gr.Interface(\n","  fn = third_model_stage1, \n","  inputs = [context, Decoding_Strategy, Word_Embedding],\n","  outputs = output)"]},{"cell_type":"markdown","metadata":{"id":"kbp3mlc1eyV0"},"source":["## Test GUI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":68391,"status":"error","timestamp":1650475715095,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"D9PjaKOdfupn","outputId":"e1647160-ffa5-4b64-e91d-7a5a8b78c773"},"outputs":[{"name":"stdout","output_type":"stream","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","Running on public URL: https://36672.gradio.app\n","\n","This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["\n","        <iframe\n","            width=\"900\"\n","            height=\"500\"\n","            src=\"https://36672.gradio.app\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x7f62d4971150>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["Cristiano ronaldo dos santos aveiro goih comm is a professional footballer from portugal. He has won five ballon d'or awards and four european golden\n","shoes - the most by european player! 'he is one of the few players to have made over 1,100 professional career appearances'\n","n_best keyphrases:  [('cristiano ronaldo', 0.11775058495563419), ('career', 0.06976319968199642), ('league titles', 0.06835673132673951), ('player', 0.06550692753228861), ('santos aveiro goih', 0.058267767302060514), ('championship', 0.03604528347689767), ('pronunciation', 0.035560509255193475), ('appearances', 0.03471596266565655), ('goals', 0.03448301764111035), ('ronaldo', 0.03417992683059817), ('kɾiʃˈtjɐnu ʁɔˈnaɫdu', 0.03236142296157868), ('trophies', 0.028414826270788663), ('uefa', 0.027138994697160322), ('premier league club manchester united', 0.026434702414690616), ('forward', 0.025963639725860452)]\n","keywords of the original text:  ['cristiano ronaldo', 'career', 'league titles', 'player', 'santos aveiro goih', 'championship', 'pronunciation', 'appearances', 'goals', 'ronaldo', 'kɾiʃˈtjɐnu ʁɔˈnaɫdu', 'trophies', 'uefa', 'premier league club manchester united', 'forward']\n","keywords of the summarized text:  ['career', 'santos aveiro goih', 'appearances', 'cristiano ronaldo', 'player']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["Wordnet distractors not found\n","Wordnet distractors not found\n","Cristiano ronaldo dos santos aveiro goih comm is a professional footballer from portugal. He has won five ballon d'or awards and four european golden\n","shoes - the most by european player! 'he is one of the few players to have made over 1,100 professional career appearances'\n","n_best keyphrases:  [('cristiano ronaldo', 0.11775058495563419), ('career', 0.06976319968199642), ('league titles', 0.06835673132673951), ('player', 0.06550692753228861), ('santos aveiro goih', 0.058267767302060514), ('championship', 0.03604528347689767), ('pronunciation', 0.035560509255193475), ('appearances', 0.03471596266565655), ('goals', 0.03448301764111035), ('ronaldo', 0.03417992683059817), ('kɾiʃˈtjɐnu ʁɔˈnaɫdu', 0.03236142296157868), ('trophies', 0.028414826270788663), ('uefa', 0.027138994697160322), ('premier league club manchester united', 0.026434702414690616), ('forward', 0.025963639725860452)]\n","keywords of the original text:  ['cristiano ronaldo', 'career', 'league titles', 'player', 'santos aveiro goih', 'championship', 'pronunciation', 'appearances', 'goals', 'ronaldo', 'kɾiʃˈtjɐnu ʁɔˈnaɫdu', 'trophies', 'uefa', 'premier league club manchester united', 'forward']\n","keywords of the summarized text:  ['career', 'santos aveiro goih', 'appearances', 'cristiano ronaldo', 'player']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-5d35d87eca00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gradio/interface.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, auth, auth_message, private_endpoint, prevent_thread_lock, show_error, server_name, server_port, show_tips, enable_queue, height, width, encrypt, cache_examples)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         is_in_interactive_mode = bool(\n\u001b[1;32m    627\u001b[0m             getattr(sys, 'ps1', sys.flags.interactive))\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"name":"stdout","output_type":"stream","text":["time: 1min 8s (started: 2022-04-20 17:27:25 +00:00)\n"]}],"source":["iface.launch(debug=True)"]},{"cell_type":"markdown","metadata":{"id":"7ehKKAcAA6T-"},"source":["# **THIRD MODEL - STAGE 2**\n","#### Note: THIRD MODEL needs to run before the FINAL MODEL runs"]},{"cell_type":"markdown","metadata":{"id":"3sU46s1eZAhW"},"source":["## Installed Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3860,"status":"ok","timestamp":1650475770988,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"Q9OcPFrgZCWY","outputId":"5e3a6ec6-e973-4eec-d083-d9505bf80b8a"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 3.64 s (started: 2022-04-20 17:29:26 +00:00)\n"]}],"source":["# library for using the Normalized Levenshtein distance\n","!pip install --quiet strsim==0.0.3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1650475770989,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"G0IdmNAJBZlM","outputId":"937d543c-6b11-4d12-f145-6865876b0e3f"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 2.24 ms (started: 2022-04-20 17:29:30 +00:00)\n"]}],"source":["from similarity.normalized_levenshtein import NormalizedLevenshtein\n","normalized_levenshtein = NormalizedLevenshtein()"]},{"cell_type":"markdown","metadata":{"id":"EsmxLNKSBfsG"},"source":["## Levenshtein Distance Filtering"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1650475766196,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"Hl2QNFmtfE1H","outputId":"03c5da1a-67ed-4766-af45-1b438a93afc9"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 4.62 ms (started: 2022-04-20 17:29:25 +00:00)\n"]}],"source":["def get_highest_similarity_score(wordlist, wrd):\n","  \"\"\"\n","  this function compares each word of the given list to the given word and finds each similarity score for returning the maximum score\n","  \"\"\"\n","\n","  score=[]\n","\n","  for each in wordlist:\n","    score.append(normalized_levenshtein.similarity(each.lower(), wrd.lower()))\n","    \n","  return max(score)"]},{"cell_type":"markdown","metadata":{"id":"fpDYkg86Bk5l"},"source":["## Base Sense Filtering"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1650475765397,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"VDfuLhckRjMW","outputId":"99fdc4d6-3de8-4ad3-8b33-324c19260829"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 8.1 ms (started: 2022-04-20 17:29:24 +00:00)\n"]}],"source":["def filter_same_sense_words(original, wordlist):\n","  \"\"\"\n","  this function's purpose is to return the words of the passing wordlist that have the same sense with the answer\n","  \"\"\"\n","\n","  filtered_words=[]\n","\n","  # get the sense\n","  base_sense = original.split('|')[1] \n","  #print(\" the base_sense is: \", base_sense)\n","\n","  # check that the words in the wordlist have the same sense with the answer\n","  # if yes => get those words and replace the underscores with a space, make their first letter uppercase and remove any leading and trailing characters\n","  for eachword in wordlist:\n","    if eachword[0].split('|')[1] == base_sense:\n","      filtered_words.append(eachword[0].split('|')[0].replace(\"_\", \" \").title().strip())\n","\n","\n","  return filtered_words"]},{"cell_type":"markdown","metadata":{"id":"pNexmGrVBsWO"},"source":["## Sense2Vec"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1650477738179,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"6lYGqAIjfFdP","outputId":"53be5bd6-052f-4ec4-96dc-4057cbbef7f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 16.2 ms (started: 2022-04-20 18:02:17 +00:00)\n"]}],"source":["def sense2vec_get_words_(question, word, topn):\n","    \"\"\"\n","    this function returns filtered distractors by doing the following:\n","    1. gets the sense of the given word\n","    2. finds the most similar words\n","    3. calls the filter_same_sense_words() function to filter the similar words to have the same sense with the given word\n","    4. applies extra filtering using three requirements \n","        - calls the get_highest_similarity_score() function for checking the similarity score using Levenshtein distance\n","        - the word has not been found before\n","        - the word is not part of the question\n","    5. returns the filtered words\n","    \"\"\"\n","\n","    output = []\n","\n","    try:\n","\n","      # if no sense => None\n","      sense = s2v.get_best_sense(word, senses= [\"NOUN\", \"PERSON\",\"PRODUCT\",\"LOC\",\"ORG\",\"EVENT\",\"NORP\",\"WORK OF ART\",\"FAC\",\"GPE\",\"NUM\",\"FACILITY\"])\n","      #print(\"the sense of the passing word is: \", sense)\n","\n","\n","      # gets a list of the n most similar ((word, sense), score) tuples\n","      most_similar = s2v.most_similar(sense, n=topn)\n","      #print (\"the most similar words of the passing word are: \", most_similar)\n","\n","\n","      output = filter_same_sense_words(sense, most_similar) # call the filter_same_sense_words() function\n","      #print (\"The words that are indeed similar (have the same base sense) are: \",output)\n","\n","    except:\n","      output =[]\n","\n","\n","    threshold = 0.6\n","    final = [word] # initialize final list with the answer\n","    checklist = question.split() # split the question into a list of strings\n","\n","    # loop through the filtered words with the same sense of the given word\n","    for x in output:\n","      # if the filtered word has similarity score less than 0.6, is not in the final list and is not part of the question => append it to the list\n","      if get_highest_similarity_score(final, x)<threshold and x.upper() not in final and x not in checklist:\n","        final.append(x)\n","    \n","    #print(\"the final list is the following: \", final)\n","    \n","    \n","    # the first word is the given answer => skip it\n","    return final[1:]"]},{"cell_type":"markdown","metadata":{"id":"lPe30nPUD31k"},"source":["## Prepare GUI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1650477734885,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"UHP_nrUigiY6","outputId":"09a2d2a4-6d72-4dda-88ef-244011d712c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 3.08 ms (started: 2022-04-20 18:02:13 +00:00)\n"]}],"source":["context = gr.inputs.Textbox(lines=10, placeholder=\"Enter paragraph/content here...\")\n","output = gr.outputs.HTML(  label=\"Question and Answers\")\n","\n","Decoding_Strategy = gr.inputs.Radio([\"Beam Search\", \"Greedy Search\", \"Sampling\", \"Sampling w Temp\", \"Top-K\", \"Top-p\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1650477735114,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"73_UVwRAgKdQ","outputId":"dfeca9eb-1356-45d7-b459-f5527c1770dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 33.2 ms (started: 2022-04-20 18:02:14 +00:00)\n"]}],"source":["def third_model_stage2(context, Decoding_Strategy):\n","\n","  # get the summary of the original text given by the user\n","  summary_text = summarizer(context,summary_model,summary_tokenizer)\n","\n","  # print the summary to the console for debugging purposes\n","  for wrp in wrap(summary_text, 150):\n","    print (wrp)\n","\n","\n","  # find the matched keywords between the original and the summarized texts\n","  np =  get_keywords(context,summary_text)\n","  \n","  # print the extracted noun keywords to the console for debugging purposes\n","  print (\"\\n\\nNoun phrases\",np)\n","  \n","\n","  output=\"\" # initialize an empty string which will be the one that will be displayed on the GUI\n","  \n","\n","  # loop through the 4 matched extracted keywords\n","  for answer in np:\n","    ques = get_question(summary_text, answer, question_model, question_tokenizer, Decoding_Strategy) # generate question for each keyword/answer\n","\n","\n","    # get distractors from Sense2Vec for the specific keyword/answer\n","    distractors = sense2vec_get_words_(ques, answer.capitalize(), 40)\n","\n","    # output= output + ques + \"\\n\" + \"Ans: \"+answer.capitalize() + \"\\n\\n\"\n","    output = output + \"<b style='color:blue;'>\" + ques + \"</b>\"\n","    output = output + \"<br>\"\n","    output = output + \"<b style='color:green;'>\" + \"Ans: \" +answer.capitalize()+  \"</b>\"+\"<br>\"\n","    if len(distractors)>0:\n","      for distractor in distractors[:3]: # add only 3 distractors\n","        output = output + \"<b style='color:brown;'>\" + distractor+  \"</b>\"+\"<br>\"\n","    output = output + \"<br>\"\n","\n","  \n","  # add \"Summary:\" prefix in the Summary variable string for displaying it on GUI\n","  summary =\"Summary: \" + \"<br>\" + summary_text\n","  \n","  \n","  # capitalize the 4 matched keywords/answers in the summarized text for better visualization in the GUI's final output\n","  for answer in np:\n","    summary = summary.replace(answer,\"<b>\" + answer+ \"</b>\")\n","    summary = summary.replace(answer.capitalize(),\"<b>\" + answer.capitalize() + \"</b>\")\n","\n","\n","  # add summarized text to the GUI's final output\n","  output = output + \"<p>\"+summary+\"</p>\"\n","  output = output + \"<br>\"\n","  \n","  return output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":913,"status":"ok","timestamp":1650477736024,"user":{"displayName":"Petros A.","userId":"16072483555613838293"},"user_tz":-180},"id":"LEKeu5cxgkk9","outputId":"c03c50f8-419c-4480-8edd-d875b129937b"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 772 ms (started: 2022-04-20 18:02:14 +00:00)\n"]}],"source":["iface = gr.Interface(\n","  fn=third_model_stage2, \n","  inputs=[context, Decoding_Strategy], \n","  outputs=output)"]},{"cell_type":"markdown","metadata":{"id":"DRCk1d30gKHZ"},"source":["## Test GUI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"abChPmnCfED-","outputId":"cd165544-d13e-46d4-db30-bc3182489132"},"outputs":[{"name":"stdout","output_type":"stream","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","Running on public URL: https://42263.gradio.app\n","\n","This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["\n","        <iframe\n","            width=\"900\"\n","            height=\"500\"\n","            src=\"https://42263.gradio.app\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x7f62d3febb90>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["The 2007 film is based on the toy line of the same name. It was directed by michael bay and produced by don murphy and tom desanto, and is the first\n","installment in the live-action transformers film series, released in january of this year, starring samuel l. eric o'donnell jr.\n","n_best keyphrases:  [('science fiction action film', 0.20181129865537317), ('toy line', 0.10832020939941245), ('name', 0.09431956887333845), ('computer animation', 0.08046707032337405), ('transformers', 0.07632735430252066), ('michael bay', 0.07082490122116103), ('steven spielberg', 0.06870046555098483), ('film', 0.05934794113013609), ('producer', 0.057033555828298554), ('action filming', 0.05109057283485087), ('installment', 0.04941538298171607), ('tom desanto', 0.048780867457206174), ('action transformers film series', 0.03356081144162786)]\n","keywords of the original text:  ['science fiction action film', 'toy line', 'name', 'computer animation', 'transformers', 'michael bay', 'steven spielberg', 'film', 'producer', 'action filming', 'installment', 'tom desanto', 'action transformers film series']\n","keywords of the summarized text:  ['film', 'name', 'toy line', 'installment', 'michael bay', 'action transformers film series', 'tom desanto']\n","\n","\n","Noun phrases ['toy line', 'name', 'michael bay', 'film']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["The 2007 film is based on the toy line of the same name. It was directed by michael bay and produced by don murphy and tom desanto, and is the first\n","installment in the live-action transformers film series, released in january of this year, starring samuel l. eric o'donnell jr.\n","n_best keyphrases:  [('science fiction action film', 0.20181129865537317), ('toy line', 0.10832020939941245), ('name', 0.09431956887333845), ('computer animation', 0.08046707032337405), ('transformers', 0.07632735430252066), ('michael bay', 0.07082490122116103), ('steven spielberg', 0.06870046555098483), ('film', 0.05934794113013609), ('producer', 0.057033555828298554), ('action filming', 0.05109057283485087), ('installment', 0.04941538298171607), ('tom desanto', 0.048780867457206174), ('action transformers film series', 0.03356081144162786)]\n","keywords of the original text:  ['science fiction action film', 'toy line', 'name', 'computer animation', 'transformers', 'michael bay', 'steven spielberg', 'film', 'producer', 'action filming', 'installment', 'tom desanto', 'action transformers film series']\n","keywords of the summarized text:  ['film', 'name', 'toy line', 'installment', 'michael bay', 'action transformers film series', 'tom desanto']\n","\n","\n","Noun phrases ['toy line', 'name', 'michael bay', 'film']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["He was awarded a phd in computer science by the technical university of ostrava, czech republic. His work was on feature selection and function\n","approximation using adaptive algorithms. The czech university of ostreva awarded him an ivf grant for his research in machine learning and signal\n","processing for pattern analysis of human's perception of the urban environment.\n","n_best keyphrases:  [('phd', 0.07860856377369267), ('computer science', 0.05896968241102518), ('pattern analysis', 0.05576039558922247), ('signal processing', 0.054031061909360585), ('human', 0.053903423319960564), ('applied mathematics', 0.05198015316401382), ('machine learning', 0.0517701697980533), ('swiss national science foundation project', 0.05069203548304731), ('perception', 0.0496213568013842), ('technical university', 0.04961343186357499), ('ostrava', 0.0489591789742317), ('eth zurich', 0.048249923772628704), ('czech republic', 0.04719548255331527), ('switzerland', 0.04475399070468492), ('environment', 0.04236668578131427)]\n","keywords of the original text:  ['phd', 'computer science', 'pattern analysis', 'signal processing', 'human', 'applied mathematics', 'machine learning', 'swiss national science foundation project', 'perception', 'technical university', 'ostrava', 'eth zurich', 'czech republic', 'switzerland', 'environment']\n","keywords of the summarized text:  ['environment', 'pattern analysis', 'ostrava', 'czech republic', 'phd', 'signal processing', 'computer science', 'human', 'technical university', 'machine learning', 'perception']\n","\n","\n","Noun phrases ['phd', 'computer science', 'pattern analysis', 'signal processing']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["He was awarded a phd in computer science and applied mathematics by the technical university of ostrava, czech republic. His phd work was on feature\n","selection and function approximation using adaptive algorithms, based on machine learning and signal processing for pattern analysis of human's\n","perception of the urban environment. Before this, dr ojha worked as an interdisciplinary research fellow in government of india funded-project on\n","mixed gases.\n","n_best keyphrases:  [('researcher', 0.06604301748257026), ('signal processing', 0.052690424471298666), ('pattern analysis', 0.05075647067495878), ('machine learning', 0.05070231261553641), ('computer science', 0.050150620976407684), ('phd', 0.0450487002220786), ('technology', 0.03963706060556339), ('eth zurich', 0.03820320685498657), ('dr ojha', 0.0359785640813622), ('human', 0.03313316867358486), ('switzerland', 0.031131089374770667), ('swiss national science foundation project', 0.03081604461473249), ('perception', 0.02968660539199123), ('applied mathematics', 0.02825624307431532), ('technical university', 0.02775188405958392)]\n","keywords of the original text:  ['researcher', 'signal processing', 'pattern analysis', 'machine learning', 'computer science', 'phd', 'technology', 'eth zurich', 'dr ojha', 'human', 'switzerland', 'swiss national science foundation project', 'perception', 'applied mathematics', 'technical university']\n","keywords of the summarized text:  ['pattern analysis', 'phd', 'signal processing', 'computer science', 'applied mathematics', 'technical university', 'human', 'dr ojha', 'machine learning', 'perception']\n","\n","\n","Noun phrases ['signal processing', 'pattern analysis', 'machine learning', 'computer science']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["He was awarded a phd in computer science by the technical university of ostrava, czech republic. His work was on feature selection and function\n","approximation using adaptive algorithms. The czech university of ostreva awarded him an ivf grant for his research in machine learning and signal\n","processing for pattern analysis of human's perception of the urban environment.\n","n_best keyphrases:  [('phd', 0.07860856377369267), ('computer science', 0.05896968241102518), ('pattern analysis', 0.05576039558922247), ('signal processing', 0.054031061909360585), ('human', 0.053903423319960564), ('applied mathematics', 0.05198015316401382), ('machine learning', 0.0517701697980533), ('swiss national science foundation project', 0.05069203548304731), ('perception', 0.0496213568013842), ('technical university', 0.04961343186357499), ('ostrava', 0.0489591789742317), ('eth zurich', 0.048249923772628704), ('czech republic', 0.04719548255331527), ('switzerland', 0.04475399070468492), ('environment', 0.04236668578131427)]\n","keywords of the original text:  ['phd', 'computer science', 'pattern analysis', 'signal processing', 'human', 'applied mathematics', 'machine learning', 'swiss national science foundation project', 'perception', 'technical university', 'ostrava', 'eth zurich', 'czech republic', 'switzerland', 'environment']\n","keywords of the summarized text:  ['environment', 'pattern analysis', 'ostrava', 'czech republic', 'phd', 'signal processing', 'computer science', 'human', 'technical university', 'machine learning', 'perception']\n","\n","\n","Noun phrases ['phd', 'computer science', 'pattern analysis', 'signal processing']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["He was awarded a phd in computer science by the technical university of ostrava, czech republic. His work was on feature selection and function\n","approximation using adaptive algorithms. The czech university of ostreva awarded him an ivf grant for his research in machine learning and signal\n","processing for pattern analysis of human's perception of the urban environment.\n","n_best keyphrases:  [('phd', 0.07860856377369267), ('computer science', 0.05896968241102518), ('pattern analysis', 0.05576039558922247), ('signal processing', 0.054031061909360585), ('human', 0.053903423319960564), ('applied mathematics', 0.05198015316401382), ('machine learning', 0.0517701697980533), ('swiss national science foundation project', 0.05069203548304731), ('perception', 0.0496213568013842), ('technical university', 0.04961343186357499), ('ostrava', 0.0489591789742317), ('eth zurich', 0.048249923772628704), ('czech republic', 0.04719548255331527), ('switzerland', 0.04475399070468492), ('environment', 0.04236668578131427)]\n","keywords of the original text:  ['phd', 'computer science', 'pattern analysis', 'signal processing', 'human', 'applied mathematics', 'machine learning', 'swiss national science foundation project', 'perception', 'technical university', 'ostrava', 'eth zurich', 'czech republic', 'switzerland', 'environment']\n","keywords of the summarized text:  ['environment', 'pattern analysis', 'ostrava', 'czech republic', 'phd', 'signal processing', 'computer science', 'human', 'technical university', 'machine learning', 'perception']\n","\n","\n","Noun phrases ['phd', 'computer science', 'pattern analysis', 'signal processing']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["He was awarded a phd in computer science by the technical university of ostrava, czech republic. His work was on feature selection and function\n","approximation using adaptive algorithms. The czech university of ostreva awarded him an ivf grant for his research in machine learning and signal\n","processing for pattern analysis of human's perception of the urban environment.\n","n_best keyphrases:  [('phd', 0.07860856377369267), ('computer science', 0.05896968241102518), ('pattern analysis', 0.05576039558922247), ('signal processing', 0.054031061909360585), ('human', 0.053903423319960564), ('applied mathematics', 0.05198015316401382), ('machine learning', 0.0517701697980533), ('swiss national science foundation project', 0.05069203548304731), ('perception', 0.0496213568013842), ('technical university', 0.04961343186357499), ('ostrava', 0.0489591789742317), ('eth zurich', 0.048249923772628704), ('czech republic', 0.04719548255331527), ('switzerland', 0.04475399070468492), ('environment', 0.04236668578131427)]\n","keywords of the original text:  ['phd', 'computer science', 'pattern analysis', 'signal processing', 'human', 'applied mathematics', 'machine learning', 'swiss national science foundation project', 'perception', 'technical university', 'ostrava', 'eth zurich', 'czech republic', 'switzerland', 'environment']\n","keywords of the summarized text:  ['environment', 'pattern analysis', 'ostrava', 'czech republic', 'phd', 'signal processing', 'computer science', 'human', 'technical university', 'machine learning', 'perception']\n","\n","\n","Noun phrases ['phd', 'computer science', 'pattern analysis', 'signal processing']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["He was awarded a phd in computer science by the technical university of ostrava, czech republic. His work was on feature selection and function\n","approximation using adaptive algorithms. The czech university of ostreva awarded him an ivf grant for his research in machine learning and signal\n","processing for pattern analysis of human's perception of the urban environment.\n","n_best keyphrases:  [('phd', 0.07860856377369267), ('computer science', 0.05896968241102518), ('pattern analysis', 0.05576039558922247), ('signal processing', 0.054031061909360585), ('human', 0.053903423319960564), ('applied mathematics', 0.05198015316401382), ('machine learning', 0.0517701697980533), ('swiss national science foundation project', 0.05069203548304731), ('perception', 0.0496213568013842), ('technical university', 0.04961343186357499), ('ostrava', 0.0489591789742317), ('eth zurich', 0.048249923772628704), ('czech republic', 0.04719548255331527), ('switzerland', 0.04475399070468492), ('environment', 0.04236668578131427)]\n","keywords of the original text:  ['phd', 'computer science', 'pattern analysis', 'signal processing', 'human', 'applied mathematics', 'machine learning', 'swiss national science foundation project', 'perception', 'technical university', 'ostrava', 'eth zurich', 'czech republic', 'switzerland', 'environment']\n","keywords of the summarized text:  ['environment', 'pattern analysis', 'ostrava', 'czech republic', 'phd', 'signal processing', 'computer science', 'human', 'technical university', 'machine learning', 'perception']\n","\n","\n","Noun phrases ['phd', 'computer science', 'pattern analysis', 'signal processing']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["He was awarded a phd in computer science by the technical university of ostrava, czech republic. His work was on feature selection and function\n","approximation using adaptive algorithms. The czech university of ostreva awarded him an ivf grant for his research in machine learning and signal\n","processing for pattern analysis of human's perception of the urban environment.\n","n_best keyphrases:  [('phd', 0.07860856377369267), ('computer science', 0.05896968241102518), ('pattern analysis', 0.05576039558922247), ('signal processing', 0.054031061909360585), ('human', 0.053903423319960564), ('applied mathematics', 0.05198015316401382), ('machine learning', 0.0517701697980533), ('swiss national science foundation project', 0.05069203548304731), ('perception', 0.0496213568013842), ('technical university', 0.04961343186357499), ('ostrava', 0.0489591789742317), ('eth zurich', 0.048249923772628704), ('czech republic', 0.04719548255331527), ('switzerland', 0.04475399070468492), ('environment', 0.04236668578131427)]\n","keywords of the original text:  ['phd', 'computer science', 'pattern analysis', 'signal processing', 'human', 'applied mathematics', 'machine learning', 'swiss national science foundation project', 'perception', 'technical university', 'ostrava', 'eth zurich', 'czech republic', 'switzerland', 'environment']\n","keywords of the summarized text:  ['environment', 'pattern analysis', 'ostrava', 'czech republic', 'phd', 'signal processing', 'computer science', 'human', 'technical university', 'machine learning', 'perception']\n","\n","\n","Noun phrases ['phd', 'computer science', 'pattern analysis', 'signal processing']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["He was awarded a phd in computer science by the technical university of ostrava, czech republic. His work was on feature selection and function\n","approximation using adaptive algorithms. The czech university of ostreva awarded him an ivf grant for his research in machine learning and signal\n","processing for pattern analysis of human's perception of the urban environment.\n","n_best keyphrases:  [('phd', 0.07860856377369267), ('computer science', 0.05896968241102518), ('pattern analysis', 0.05576039558922247), ('signal processing', 0.054031061909360585), ('human', 0.053903423319960564), ('applied mathematics', 0.05198015316401382), ('machine learning', 0.0517701697980533), ('swiss national science foundation project', 0.05069203548304731), ('perception', 0.0496213568013842), ('technical university', 0.04961343186357499), ('ostrava', 0.0489591789742317), ('eth zurich', 0.048249923772628704), ('czech republic', 0.04719548255331527), ('switzerland', 0.04475399070468492), ('environment', 0.04236668578131427)]\n","keywords of the original text:  ['phd', 'computer science', 'pattern analysis', 'signal processing', 'human', 'applied mathematics', 'machine learning', 'swiss national science foundation project', 'perception', 'technical university', 'ostrava', 'eth zurich', 'czech republic', 'switzerland', 'environment']\n","keywords of the summarized text:  ['environment', 'pattern analysis', 'ostrava', 'czech republic', 'phd', 'signal processing', 'computer science', 'human', 'technical university', 'machine learning', 'perception']\n","\n","\n","Noun phrases ['phd', 'computer science', 'pattern analysis', 'signal processing']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["He was awarded a phd in computer science by the technical university of ostrava, czech republic. His work was on feature selection and function\n","approximation using adaptive algorithms. The czech university of ostreva awarded him an ivf grant for his research in machine learning and signal\n","processing for pattern analysis of human's perception of the urban environment.\n","n_best keyphrases:  [('phd', 0.07860856377369267), ('computer science', 0.05896968241102518), ('pattern analysis', 0.05576039558922247), ('signal processing', 0.054031061909360585), ('human', 0.053903423319960564), ('applied mathematics', 0.05198015316401382), ('machine learning', 0.0517701697980533), ('swiss national science foundation project', 0.05069203548304731), ('perception', 0.0496213568013842), ('technical university', 0.04961343186357499), ('ostrava', 0.0489591789742317), ('eth zurich', 0.048249923772628704), ('czech republic', 0.04719548255331527), ('switzerland', 0.04475399070468492), ('environment', 0.04236668578131427)]\n","keywords of the original text:  ['phd', 'computer science', 'pattern analysis', 'signal processing', 'human', 'applied mathematics', 'machine learning', 'swiss national science foundation project', 'perception', 'technical university', 'ostrava', 'eth zurich', 'czech republic', 'switzerland', 'environment']\n","keywords of the summarized text:  ['environment', 'pattern analysis', 'ostrava', 'czech republic', 'phd', 'signal processing', 'computer science', 'human', 'technical university', 'machine learning', 'perception']\n","\n","\n","Noun phrases ['phd', 'computer science', 'pattern analysis', 'signal processing']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["He was awarded a phd in computer science by the technical university of ostrava, czech republic. His work was on feature selection and function\n","approximation using adaptive algorithms. The czech university of ostreva awarded him an ivf grant for his research in machine learning and signal\n","processing for pattern analysis of human's perception of the urban environment.\n","n_best keyphrases:  [('phd', 0.07860856377369267), ('computer science', 0.05896968241102518), ('pattern analysis', 0.05576039558922247), ('signal processing', 0.054031061909360585), ('human', 0.053903423319960564), ('applied mathematics', 0.05198015316401382), ('machine learning', 0.0517701697980533), ('swiss national science foundation project', 0.05069203548304731), ('perception', 0.0496213568013842), ('technical university', 0.04961343186357499), ('ostrava', 0.0489591789742317), ('eth zurich', 0.048249923772628704), ('czech republic', 0.04719548255331527), ('switzerland', 0.04475399070468492), ('environment', 0.04236668578131427)]\n","keywords of the original text:  ['phd', 'computer science', 'pattern analysis', 'signal processing', 'human', 'applied mathematics', 'machine learning', 'swiss national science foundation project', 'perception', 'technical university', 'ostrava', 'eth zurich', 'czech republic', 'switzerland', 'environment']\n","keywords of the summarized text:  ['environment', 'pattern analysis', 'ostrava', 'czech republic', 'phd', 'signal processing', 'computer science', 'human', 'technical university', 'machine learning', 'perception']\n","\n","\n","Noun phrases ['phd', 'computer science', 'pattern analysis', 'signal processing']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["He was awarded a phd in computer science by the technical university of ostrava, czech republic. His work was on feature selection and function\n","approximation using adaptive algorithms. The czech university of ostreva awarded him an ivf grant for his research in machine learning and signal\n","processing for pattern analysis of human's perception of the urban environment.\n","n_best keyphrases:  [('phd', 0.07860856377369267), ('computer science', 0.05896968241102518), ('pattern analysis', 0.05576039558922247), ('signal processing', 0.054031061909360585), ('human', 0.053903423319960564), ('applied mathematics', 0.05198015316401382), ('machine learning', 0.0517701697980533), ('swiss national science foundation project', 0.05069203548304731), ('perception', 0.0496213568013842), ('technical university', 0.04961343186357499), ('ostrava', 0.0489591789742317), ('eth zurich', 0.048249923772628704), ('czech republic', 0.04719548255331527), ('switzerland', 0.04475399070468492), ('environment', 0.04236668578131427)]\n","keywords of the original text:  ['phd', 'computer science', 'pattern analysis', 'signal processing', 'human', 'applied mathematics', 'machine learning', 'swiss national science foundation project', 'perception', 'technical university', 'ostrava', 'eth zurich', 'czech republic', 'switzerland', 'environment']\n","keywords of the summarized text:  ['environment', 'pattern analysis', 'ostrava', 'czech republic', 'phd', 'signal processing', 'computer science', 'human', 'technical university', 'machine learning', 'perception']\n","\n","\n","Noun phrases ['phd', 'computer science', 'pattern analysis', 'signal processing']\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1839: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]},{"name":"stdout","output_type":"stream","text":["He was awarded a phd in computer science by the technical university of ostrava, czech republic. His work was on feature selection and function\n","approximation using adaptive algorithms. The czech university of ostreva awarded him an ivf grant for his research in machine learning and signal\n","processing for pattern analysis of human's perception of the urban environment.\n","n_best keyphrases:  [('phd', 0.07860856377369267), ('computer science', 0.05896968241102518), ('pattern analysis', 0.05576039558922247), ('signal processing', 0.054031061909360585), ('human', 0.053903423319960564), ('applied mathematics', 0.05198015316401382), ('machine learning', 0.0517701697980533), ('swiss national science foundation project', 0.05069203548304731), ('perception', 0.0496213568013842), ('technical university', 0.04961343186357499), ('ostrava', 0.0489591789742317), ('eth zurich', 0.048249923772628704), ('czech republic', 0.04719548255331527), ('switzerland', 0.04475399070468492), ('environment', 0.04236668578131427)]\n","keywords of the original text:  ['phd', 'computer science', 'pattern analysis', 'signal processing', 'human', 'applied mathematics', 'machine learning', 'swiss national science foundation project', 'perception', 'technical university', 'ostrava', 'eth zurich', 'czech republic', 'switzerland', 'environment']\n","keywords of the summarized text:  ['environment', 'pattern analysis', 'ostrava', 'czech republic', 'phd', 'signal processing', 'computer science', 'human', 'technical university', 'machine learning', 'perception']\n","\n","\n","Noun phrases ['phd', 'computer science', 'pattern analysis', 'signal processing']\n"]}],"source":["iface.launch(debug=True)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["nL33UMx9U_G5","n5EKQ4r7KEJf","dvaYa_e5epC3","vWeUtAiDexVo","I51vKezENsue","Kul4z9SBbT3T","OXAaiQNVQyrS","xkmWZEQqIya9","yjApievUI5BR","kQQcHzdpI9-V","x_onxX5hJBMX","yKdFjuBRJJ2J","2hc7kP7bJQOz","OgCr8K7hJ_bk","jm4PVXSoRRBb","fLmz4p69C8ZX","kbp3mlc1eyV0","3sU46s1eZAhW","EsmxLNKSBfsG","fpDYkg86Bk5l","pNexmGrVBsWO","lPe30nPUD31k","DRCk1d30gKHZ"],"name":"Final_Model.ipynb","provenance":[],"authorship_tag":"ABX9TyPJrLkLIzdoM+7m9p8iNh0t"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}